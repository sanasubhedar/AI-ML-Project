{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":256618,"sourceType":"datasetVersion","datasetId":107620},{"sourceId":639622,"sourceType":"datasetVersion","datasetId":316368},{"sourceId":653195,"sourceType":"datasetVersion","datasetId":325566},{"sourceId":671851,"sourceType":"datasetVersion","datasetId":338555},{"sourceId":2956232,"sourceType":"datasetVersion","datasetId":1812476}],"dockerImageVersionId":30154,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Keras\nimport keras\nfrom keras import regularizers\nfrom keras.preprocessing import sequence\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences\nfrom keras.models import Sequential, Model, model_from_json\nfrom keras.layers import Dense, Embedding, LSTM\nfrom keras.layers import Input, Flatten, Dropout, Activation, BatchNormalization\nfrom keras.layers import Conv1D, MaxPooling1D, AveragePooling1D\nfrom keras.utils import np_utils\nfrom tensorflow.keras.utils import to_categorical\nfrom keras.callbacks import (EarlyStopping, LearningRateScheduler,\n                             ModelCheckpoint, TensorBoard, ReduceLROnPlateau)\nfrom keras import losses, models, optimizers\nfrom keras.activations import relu, softmax\nfrom keras.layers import (Convolution2D, GlobalAveragePooling2D, BatchNormalization, Flatten, Dropout,\n                          GlobalMaxPool2D, MaxPool2D, concatenate, Activation, Input, Dense)\n\n# sklearn\nfrom sklearn.metrics import confusion_matrix, accuracy_score\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\n\n# Other  \nfrom tqdm import tqdm, tqdm_pandas\nimport scipy\nfrom scipy.stats import skew\nimport librosa\nimport librosa.display\nimport json\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nfrom matplotlib.pyplot import specgram\nimport pandas as pd\nimport seaborn as sns\nimport glob \nimport os\nimport sys\nimport IPython.display as ipd  # To play sound in the notebook\nimport warnings\n# ignore warnings \nif not sys.warnoptions:\n    warnings.simplefilter(\"ignore\")","metadata":{"execution":{"iopub.status.busy":"2023-11-29T03:56:40.874439Z","iopub.execute_input":"2023-11-29T03:56:40.874848Z","iopub.status.idle":"2023-11-29T03:56:50.901412Z","shell.execute_reply.started":"2023-11-29T03:56:40.874745Z","shell.execute_reply":"2023-11-29T03:56:50.900284Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 1. Custom functions\nSo we'll be building some custom functions to extract various features.\nThe 2D CNN takes in a 2D array of 30 MFCC bands by 216 audio length as input data. so just imagine it as a 30 x 216 pixel image.\nAnd just like in images, we could inlude a 3rd Dimension, but that's a topic for another time. \nIt's got 4 convolution blocks of batch normalisation, max pooling and a dropout node.\nSo your standard setup similar to VGG19, just not as deep. And we're using Adam for our optimiser.\n\nFor printing our results, i've created a class instead to encapsulate the various attributes. So that way I don't have to repeat the same code many times.\n\n\n","metadata":{}},{"cell_type":"code","source":"'''\n1. Data Augmentation method   \n'''\ndef speedNpitch(data):\n    \"\"\"\n    Speed and Pitch Tuning.\n    \"\"\"\n    # you can change low and high here\n    length_change = np.random.uniform(low=0.8, high = 1)\n    speed_fac = 1.2  / length_change # try changing 1.0 to 2.0 ... =D\n    tmp = np.interp(np.arange(0,len(data),speed_fac),np.arange(0,len(data)),data)\n    minlen = min(data.shape[0], tmp.shape[0])\n    data *= 0\n    data[0:minlen] = tmp[0:minlen]\n    return data\n\n'''\n2. Extracting the MFCC feature as an image (Matrix format).  \n'''\ndef prepare_data(df, n, aug, mfcc):\n    X = np.empty(shape=(df.shape[0], n, 216, 1))\n    input_length = sampling_rate * audio_duration\n    \n    cnt = 0\n    for fname in tqdm(df.path):\n        file_path = fname\n        data, _ = librosa.load(file_path, sr=sampling_rate\n                               ,res_type=\"kaiser_fast\"\n                               ,duration=2.5\n                               ,offset=0.5\n                              )\n\n        # Random offset / Padding\n        if len(data) > input_length:\n            max_offset = len(data) - input_length\n            offset = np.random.randint(max_offset)\n            data = data[offset:(input_length+offset)]\n        else:\n            if input_length > len(data):\n                max_offset = input_length - len(data)\n                offset = np.random.randint(max_offset)\n            else:\n                offset = 0\n            data = np.pad(data, (offset, int(input_length) - len(data) - offset), \"constant\")\n\n        # Augmentation? \n        if aug == 1:\n            data = speedNpitch(data)\n        \n        # which feature?\n        if mfcc == 1:\n            # MFCC extraction \n            MFCC = librosa.feature.mfcc(data, sr=sampling_rate, n_mfcc=n_mfcc)\n            MFCC = np.expand_dims(MFCC, axis=-1)\n            X[cnt,] = MFCC\n            \n        else:\n            # Log-melspectogram\n            melspec = librosa.feature.melspectrogram(data, n_mels = n_melspec)   \n            logspec = librosa.amplitude_to_db(melspec)\n            logspec = np.expand_dims(logspec, axis=-1)\n            X[cnt,] = logspec\n            \n        cnt += 1\n    \n    return X\n\n\n'''\n3. Confusion matrix plot \n'''        \ndef print_confusion_matrix(confusion_matrix, class_names, figsize = (10,7), fontsize=14):\n    '''Prints a confusion matrix, as returned by sklearn.metrics.confusion_matrix, as a heatmap.\n\n    Arguments\n    ---------\n    confusion_matrix: numpy.ndarray\n        The numpy.ndarray object returned from a call to sklearn.metrics.confusion_matrix. \n        Similarly constructed ndarrays can also be used.\n    class_names: list\n        An ordered list of class names, in the order they index the given confusion matrix.\n    figsize: tuple\n        A 2-long tuple, the first value determining the horizontal size of the ouputted figure,\n        the second determining the vertical size. Defaults to (10,7).\n    fontsize: int\n        Font size for axes labels. Defaults to 14.\n\n    Returns\n    -------\n    matplotlib.figure.Figure\n        The resulting confusion matrix figure\n    '''\n    df_cm = pd.DataFrame(\n        confusion_matrix, index=class_names, columns=class_names, \n    )\n    fig = plt.figure(figsize=figsize)\n    try:\n        heatmap = sns.heatmap(df_cm, annot=True, fmt=\"d\")\n    except ValueError:\n        raise ValueError(\"Confusion matrix values must be integers.\")\n\n    heatmap.yaxis.set_ticklabels(heatmap.yaxis.get_ticklabels(), rotation=0, ha='right', fontsize=fontsize)\n    heatmap.xaxis.set_ticklabels(heatmap.xaxis.get_ticklabels(), rotation=45, ha='right', fontsize=fontsize)\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n\n    \n    \n'''\n# 4. Create the 2D CNN model \n'''\ndef get_2d_conv_model(n):\n    ''' Create a standard deep 2D convolutional neural network'''\n    nclass = 14\n    inp = Input(shape=(n,216,1))  #2D matrix of 30 MFCC bands by 216 audio length.\n    x = Convolution2D(32, (4,10), padding=\"same\")(inp)\n    x = BatchNormalization()(x)\n    x = Activation(\"relu\")(x)\n    x = MaxPool2D()(x)\n    x = Dropout(rate=0.2)(x)\n    \n    x = Convolution2D(32, (4,10), padding=\"same\")(x)\n    x = BatchNormalization()(x)\n    x = Activation(\"relu\")(x)\n    x = MaxPool2D()(x)\n    x = Dropout(rate=0.2)(x)\n    \n    x = Convolution2D(32, (4,10), padding=\"same\")(x)\n    x = BatchNormalization()(x)\n    x = Activation(\"relu\")(x)\n    x = MaxPool2D()(x)\n    x = Dropout(rate=0.2)(x)\n    \n    x = Convolution2D(32, (4,10), padding=\"same\")(x)\n    x = BatchNormalization()(x)\n    x = Activation(\"relu\")(x)\n    x = MaxPool2D()(x)\n    x = Dropout(rate=0.2)(x)\n    \n    x = Flatten()(x)\n    x = Dense(64)(x)\n    x = Dropout(rate=0.2)(x)\n    x = BatchNormalization()(x)\n    x = Activation(\"relu\")(x)\n    x = Dropout(rate=0.2)(x)\n    \n    out = Dense(nclass, activation=softmax)(x)\n    model = models.Model(inputs=inp, outputs=out)\n    \n    opt = tf.keras.optimizers.Adam(0.001)\n    model.compile(optimizer=opt, loss=losses.categorical_crossentropy, metrics=['acc'])\n    return model\n\n'''\n# 5. Other functions \n'''\nclass get_results:\n    '''\n    We're going to create a class (blueprint template) for generating the results based on the various model approaches. \n    So instead of repeating the functions each time, we assign the results into on object with its associated variables \n    depending on each combination:\n        1) MFCC with no augmentation  \n        2) MFCC with augmentation \n        3) Logmelspec with no augmentation \n        4) Logmelspec with augmentation\n    '''\n    \n    def __init__(self, model_history, model ,X_test, y_test, labels):\n        self.model_history = model_history\n        self.model = model\n        self.X_test = X_test\n        self.y_test = y_test             \n        self.labels = labels\n\n    def create_plot(self, model_history):\n        '''Check the logloss of both train and validation, make sure they are close and have plateau'''\n        plt.plot(model_history.history['loss'])\n        plt.plot(model_history.history['val_loss'])\n        plt.title('model loss')\n        plt.ylabel('loss')\n        plt.xlabel('epoch')\n        plt.legend(['train', 'test'], loc='upper left')\n        plt.show()\n\n    def create_results(self, model):\n        '''predict on test set and get accuracy results'''\n        opt = tf.keras.optimizers.Adam(0.001)\n        model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n        score = model.evaluate(X_test, y_test, verbose=0)\n        print(\"%s: %.2f%%\" % (model.metrics_names[1], score[1]*100))\n\n    def confusion_results(self, X_test, y_test, labels, model):\n        '''plot confusion matrix results'''\n        preds = model.predict(X_test, \n                                 batch_size=16, \n                                 verbose=2)\n        preds=preds.argmax(axis=1)\n        preds = preds.astype(int).flatten()\n        preds = (lb.inverse_transform((preds)))\n\n        actual = y_test.argmax(axis=1)\n        actual = actual.astype(int).flatten()\n        actual = (lb.inverse_transform((actual)))\n\n        classes = labels\n        classes.sort()    \n\n        c = confusion_matrix(actual, preds)\n        print_confusion_matrix(c, class_names = classes)\n    \n    def accuracy_results_gender(self, X_test, y_test, labels, model):\n        '''Print out the accuracy score and confusion matrix heat map of the Gender classification results'''\n    \n        preds = model.predict(X_test, \n                         batch_size=16, \n                         verbose=2)\n        preds=preds.argmax(axis=1)\n        preds = preds.astype(int).flatten()\n        preds = (lb.inverse_transform((preds)))\n\n        actual = y_test.argmax(axis=1)\n        actual = actual.astype(int).flatten()\n        actual = (lb.inverse_transform((actual)))\n        \n        # print(accuracy_score(actual, preds))\n        \n        actual = pd.DataFrame(actual).replace({'female_angry':'female'\n                   , 'female_disgust':'female'\n                   , 'female_fear':'female'\n                   , 'female_happy':'female'\n                   , 'female_sad':'female'\n                   , 'female_surprise':'female'\n                   , 'female_neutral':'female'\n                   , 'male_angry':'male'\n                   , 'male_fear':'male'\n                   , 'male_happy':'male'\n                   , 'male_sad':'male'\n                   , 'male_surprise':'male'\n                   , 'male_neutral':'male'\n                   , 'male_disgust':'male'\n                  })\n        preds = pd.DataFrame(preds).replace({'female_angry':'female'\n               , 'female_disgust':'female'\n               , 'female_fear':'female'\n               , 'female_happy':'female'\n               , 'female_sad':'female'\n               , 'female_surprise':'female'\n               , 'female_neutral':'female'\n               , 'male_angry':'male'\n               , 'male_fear':'male'\n               , 'male_happy':'male'\n               , 'male_sad':'male'\n               , 'male_surprise':'male'\n               , 'male_neutral':'male'\n               , 'male_disgust':'male'\n              })\n\n        classes = actual.loc[:,0].unique() \n        classes.sort()    \n\n        c = confusion_matrix(actual, preds)\n        print(accuracy_score(actual, preds))\n        print_confusion_matrix(c, class_names = classes)","metadata":{"execution":{"iopub.status.busy":"2023-11-29T03:56:50.903955Z","iopub.execute_input":"2023-11-29T03:56:50.904499Z","iopub.status.idle":"2023-11-29T03:56:50.963452Z","shell.execute_reply.started":"2023-11-29T03:56:50.904456Z","shell.execute_reply":"2023-11-29T03:56:50.962420Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ref = pd.read_csv(\"/kaggle/input/data-path/Data_path.csv\")\nref.head()","metadata":{"execution":{"iopub.status.busy":"2023-11-29T03:56:50.964714Z","iopub.execute_input":"2023-11-29T03:56:50.964950Z","iopub.status.idle":"2023-11-29T03:56:51.060505Z","shell.execute_reply.started":"2023-11-29T03:56:50.964920Z","shell.execute_reply":"2023-11-29T03:56:51.059162Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 2. MFCC without augmentation\n\nNow we shall use the entire MFCC data and treat it as an image, and push it through to a 2D CNN instead of a 1D CNN. \n\n**This will be without data augmentation for now.** \n\nThe convergence is very quick so instead of letting it run over 50 or more epochs, we will just cut it at 20","metadata":{}},{"cell_type":"code","source":"sampling_rate=44100\naudio_duration=2.5\nn_mfcc = 30\nmfcc = prepare_data(ref, n = n_mfcc, aug = 0, mfcc = 1)","metadata":{"execution":{"iopub.status.busy":"2023-11-29T03:56:51.063824Z","iopub.execute_input":"2023-11-29T03:56:51.064185Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Split between train and test \nX_train, X_test, y_train, y_test = train_test_split(mfcc\n                                                    , ref.labels\n                                                    , test_size=0.25\n                                                    , shuffle=True\n                                                    , random_state=42\n                                                   )\n\n\n# one hot encode the target \nlb = LabelEncoder()\ny_train = np_utils.to_categorical(lb.fit_transform(y_train))\ny_test = np_utils.to_categorical(lb.fit_transform(y_test))\n\n# Normalization as per the standard NN process\nmean = np.mean(X_train, axis=0)\nstd = np.std(X_train, axis=0)\n\nX_train = (X_train - mean)/std\nX_test = (X_test - mean)/std\n\n# Build CNN model \nmodel = get_2d_conv_model(n=n_mfcc)\nmodel_history = model.fit(X_train, y_train, validation_data=(X_test, y_test), \n                    batch_size=16, verbose = 2, epochs=20)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"results = get_results(model_history,model,X_test,y_test, ref.labels.unique())\nresults.create_plot(model_history)\nresults.create_results(model)\nresults.confusion_results(X_test, y_test, ref.labels.unique(), model)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 3. MFCC with Augmentation\n","metadata":{}},{"cell_type":"code","source":"sampling_rate=44100\naudio_duration=2.5\nn_mfcc = 30\nmfcc_aug = prepare_data(ref, n = n_mfcc, aug = 1, mfcc = 1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Split between train and test \nX_train, X_test, y_train, y_test = train_test_split(mfcc_aug\n                                                    , ref.labels\n                                                    , test_size=0.25\n                                                    , shuffle=True\n                                                    , random_state=42\n                                                   )\n\n# one hot encode the target \nlb = LabelEncoder()\ny_train = np_utils.to_categorical(lb.fit_transform(y_train))\ny_test = np_utils.to_categorical(lb.fit_transform(y_test))\n\n# Normalization as per the standard NN process\n# mean = np.mean(X_train, axis=0)\n# std = np.std(X_train, axis=0)\n\n# X_train = (X_train - mean)/std\n# X_test = (X_test - mean)/std\n\n# Build CNN model \nmodel = get_2d_conv_model(n=n_mfcc)\nmodel_history = model.fit(X_train, y_train, validation_data=(X_test, y_test), \n                    batch_size=16, verbose = 2, epochs=20)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"results = get_results(model_history,model,X_test,y_test, ref.labels.unique())\nresults.create_plot(model_history)\nresults.create_results(model)\nresults.confusion_results(X_test, y_test, ref.labels.unique(), model)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 4. Log-melspectogram without augmentation\n\nThe accuracy is 60%, a slight drop from 64% without augmentation which is interesting and slightly unexpected. The plot of the logloss also indicates that it's converged.","metadata":{}},{"cell_type":"code","source":"sampling_rate=44100\naudio_duration=2.5\nn_melspec = 60\nspecgram = prepare_data(ref, n = n_melspec, aug = 0, mfcc = 0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Split between train and test \nX_train, X_test, y_train, y_test = train_test_split(specgram\n                                                    , ref.labels\n                                                    , test_size=0.25\n                                                    , shuffle=True\n                                                    , random_state=42\n                                                   )\n\n\n\n# one hot encode the target jh\nlb = LabelEncoder()\ny_train = np_utils.to_categorical(lb.fit_transform(y_train))\ny_test = np_utils.to_categorical(lb.fit_transform(y_test))\n\n# Normalization as per the standard NN process\nmean = np.mean(X_train, axis=0)\nstd = np.std(X_train, axis=0)\n\nX_train = (X_train - mean)/std\nX_test = (X_test - mean)/std\n\n# Build CNN model \nmodel = get_2d_conv_model(n=n_melspec)\nmodel_history = model.fit(X_train, y_train, validation_data=(X_test, y_test), \n                    batch_size=16, verbose = 2, epochs=20)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"results = get_results(model_history,model,X_test,y_test, ref.labels.unique())\nresults.create_plot(model_history)\nresults.create_results(model)\nresults.confusion_results(X_test, y_test, ref.labels.unique(), model)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 5. Log-melspectogram with augmentation\n\n63% accuracy for a log-melspectogram. Slighlty lower than MFCC but very close. Notice however from the logloss plot, the log-melspectogram accuracy potential hasn't quite plateau yet. It's likely that higher number of epochs the accuracy could surpass that of the MFCC, albeit slightly","metadata":{}},{"cell_type":"code","source":"sampling_rate=44100\naudio_duration=2.5\nn_melspec = 60\naug_specgram = prepare_data(ref,  n = n_melspec, aug = 1, mfcc = 0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Split between train and test \nX_train, X_test, y_train, y_test = train_test_split(aug_specgram\n                                                    , ref.labels\n                                                    , test_size=0.25\n                                                    , shuffle=True\n                                                    , random_state=42\n                                                   )\n\n\n\n# one hot encode the target \nlb = LabelEncoder()\ny_train = np_utils.to_categorical(lb.fit_transform(y_train))\ny_test = np_utils.to_categorical(lb.fit_transform(y_test))\n\n# Normalization as per the standard NN process\nmean = np.mean(X_train, axis=0)\nstd = np.std(X_train, axis=0)\n\nX_train = (X_train - mean)/std\nX_test = (X_test - mean)/std\n\n# Build CNN model \nmodel = get_2d_conv_model(n=n_melspec)\nmodel_history = model.fit(X_train, y_train, validation_data=(X_test, y_test), \n                    batch_size=16, verbose = 2, epochs=20)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"results = get_results(model_history,model,X_test,y_test, ref.labels.unique())\nresults.create_plot(model_history)\nresults.create_results(model)\nresults.confusion_results(X_test, y_test, ref.labels.unique(), model)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"All the 2D CNN models seems to do better than the 1D CNN model","metadata":{}},{"cell_type":"code","source":"results.accuracy_results_gender(X_test, y_test, ref.labels.unique(), model)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import librosa\nimport librosa.display\nimport json\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nfrom matplotlib.pyplot import specgram\nimport pandas as pd\nimport seaborn as sns\nimport glob \nimport os\nfrom tqdm import tqdm\nimport pickle\nimport IPython.display as ipd  # To play sound in the notebook","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.models import Sequential, Model, model_from_json","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Save model and weights\nmodel = Sequential()\nmodel_name = '2D_cnn.h5'\nsave_dir = os.path.join(os.getcwd(), 'saved_models')\n\n# Save the model to disk\nmodel_json = model.to_json()\nwith open(\"model_json_2dcnn.json\", \"w\") as json_file:\n    json_file.write(model_json)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}
